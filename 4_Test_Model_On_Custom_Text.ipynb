{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_and_counts(source_text , answer_text, n):\n",
    "    counts_ngram = CountVectorizer(analyzer='word', ngram_range=(n,n))\n",
    "    vocab = counts_ngram.fit([answer_text, source_text]).vocabulary_\n",
    "    counts = counts_ngram.fit_transform([answer_text, source_text])\n",
    "    \n",
    "    return vocab, counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_containment(n,source_text , answer_text):\n",
    "\n",
    "    vocab, ngram_counts = get_vocab_and_counts(answer_text = answer_text, source_text = source_text, n = n)\n",
    "    \n",
    "    intersection_list = np.amin(ngram_counts, axis = 0) # intersection of counts, taking min column-wise\n",
    "\n",
    "    intersection = np.sum(intersection_list) # summing the intersection count\n",
    "    count_ngram_A = np.sum(ngram_counts[0]) # normalizer\n",
    "\n",
    "    return intersection / count_ngram_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs_norm_word(source_text , answer_text):\n",
    "    \n",
    "    # separate into list entries to simulate matrix\n",
    "    answer_words = answer_text.split()\n",
    "    source_words = source_text.split()\n",
    "    \n",
    "    n = len(answer_words)\n",
    "    m = len(source_words)\n",
    "    \n",
    "    \n",
    "    lcs_matrix = np.zeros((n+1, m+1))\n",
    "    \n",
    "    # iterate thru words, finding longest common subsequence using dynamic programming\n",
    "    i = j = 1\n",
    "    for answer_word in answer_words:\n",
    "        j = 1\n",
    "        for source_word in source_words:\n",
    "            if answer_word == source_word:\n",
    "                lcs_matrix[i][j] = lcs_matrix[i-1][j-1] + 1\n",
    "            else:\n",
    "                lcs_matrix[i][j] = max(lcs_matrix[i][j-1], lcs_matrix[i-1][j]) \n",
    "            \n",
    "            j += 1\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "    lcs_normalized = lcs_matrix[n][m] / n\n",
    "    \n",
    "    return lcs_normalized\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_containment_features( n, source_text , answer_text, column_name=None):\n",
    "    \n",
    "    containment_values = []\n",
    "    \n",
    "    if(column_name==None):\n",
    "        column_name = 'c_'+str(n) # c_1, c_2, .. c_n\n",
    "    \n",
    "    c = calculate_containment( n, answer_text=answer_text, source_text = source_text)\n",
    "    containment_values.append(c)\n",
    "    print(str(n)+'-gram containment features created!')\n",
    "    return containment_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lcs_features(source_text , answer_text):\n",
    "    \n",
    "    lcs_values = []\n",
    "    lcs = lcs_norm_word(answer_text = answer_text, source_text=source_text)\n",
    "    lcs_values.append(lcs)\n",
    "    print('LCS features created!')\n",
    "    return lcs_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Containment and LCS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_containment_and_lcs_features(source_text, answer_text):\n",
    "\n",
    "    # Define an ngram range\n",
    "    ngram_range = range(1,8)\n",
    "\n",
    "    features_list = []\n",
    "\n",
    "    # Create features in a features_df\n",
    "    all_features = np.zeros((len(ngram_range)+1, 1))\n",
    "\n",
    "    # Calculate features for containment for ngrams in range\n",
    "    i=0\n",
    "    for n in ngram_range:\n",
    "        column_name = 'c_'+str(n)\n",
    "        features_list.append(column_name)\n",
    "        # create containment features\n",
    "        all_features[i]=np.squeeze(create_containment_features(source_text=source_text, answer_text=answer_text ,n=n))\n",
    "        i+=1\n",
    "\n",
    "    # Calculate features for LCS_Norm Words \n",
    "    features_list.append('lcs_word')\n",
    "\n",
    "    all_features[i]= np.squeeze(create_lcs_features(answer_text=answer_text , source_text=source_text))\n",
    "\n",
    "    # create a features dataframe\n",
    "    features_df = pd.DataFrame(np.transpose(all_features), columns=features_list)\n",
    "\n",
    "    # Print all features/columns\n",
    "    print()\n",
    "    print('Features: ', features_list)\n",
    "    print()\n",
    "\n",
    "    return features_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "clf_en = load('pretrained model/saved_model_v1.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Your Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text_1 = \"\"\"\n",
    "In object-oriented programming, inheritance is a way to form new classes (instances of which are called objects) using classes that have already been defined. The inheritance concept was invented in 1967 for Simula.\n",
    "\n",
    "The new classes, known as derived classes, take over (or inherit) attributes and behavior of the pre-existing classes, which are referred to as base classes (or ancestor classes). It is intended to help reuse existing code with little or no modification.\n",
    "\n",
    "Inheritance provides the support for representation by categorization in computer languages. Categorization is a powerful mechanism number of information processing, crucial to human learning by means of generalization (what is known about specific entities is applied to a wider group given a belongs relation can be established) and cognitive economy (less information needs to be stored about each specific entity, only its particularities).\n",
    "\n",
    "Inheritance is also sometimes called generalization, because the is-a relationships represent a hierarchy between classes of objects. For instance, a \"fruit\" is a generalization of \"apple\", \"orange\", \"mango\" and many others. One can consider fruit to be an abstraction of apple, orange, etc. Conversely, since apples are fruit (i.e., an apple is-a fruit), apples may naturally inherit all the properties common to all fruit, such as being a fleshy container for the seed of a plant.\n",
    "\n",
    "An advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code, reducing the complexity of the program. Inheritance therefore has another view, a dual, called polymorphism, which describes many pieces of code being controlled by shared control code.\n",
    "Inheritance is typically accomplished either by overriding (replacing) one or more methods exposed by ancestor, or by adding new methods to those exposed by an ancestor.\n",
    "\n",
    "Complex inheritance, or inheritance used within a design that is not sufficiently mature, may lead to the Yo-yo problem.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_text_1 =\"\"\"\n",
    "In object-oriented programming, inheritance is a way to form new classes (instances of which are called objects) using classes that have already been defined. The inheritance concept was invented in 1967 for Simula.\n",
    "\n",
    "The new classeit) attributes and behavior of the pre-existing classes, which are referred to as base classes (or ancestor classes). It is intended to help reuse existing code with little or no modification.\n",
    "\n",
    "Inheritance prization in computer languages. Categorization is a powerful mechanism number of information processing, crucial to human learning by means of generalization (what is known about specific entities is applied to a wider group given a belongs relation can be established) and cognitive economy (less information needs to be stored about each specific entity, only its particularities).\n",
    "\n",
    "Inheritance ishe is-a relationships represent a hierarchy between classes of objects. For instance, a \"fruit\" is a generalization of \"apple\", \"orange\", \"mango\" and many others. One can consider fruit to be an abstraction of apple, orange, etc. Conversely, since apples are fruit (i.e., an apple is-a fruit), apples may naturally inherit all the properties common to all fruit, such as being a fleshy container for the seed of a plant.\n",
    "\n",
    "An advantage osimilar interfaces can share a lot of code, reducing the complexity of the program. Inheritance therefore has another view, a dual, called polymorphism, which describes many pieces of code being controlled by shared control code.\n",
    "Inheritance is typically accomplished either by overriding (replacing) one or more methods exposed by ancestor, or by adding new methods to those exposed by an ancestor.\n",
    "\n",
    "Complex inheritance, or inheritance used within a design that is not sufficiently mature, may lead to the Yo-yo problem.\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text_2 = \"\"\"\n",
    "Vector space model (or term vector model) is an algebraic model for representing text documents (and any objects, in general) as vectors of identifiers, such as, for example, index terms. It is used in information filtering, information retrieval, indexing and relevancy rankings. Its first use was in the SMART Information Retrieval System.\n",
    "A document is represented as a vector. Each dimension corresponds to a separate term. If a term occurs in the document, its value in the vector is non-zero. Several different ways of computing these values, also known as (term) weights, have been developed. One of the best known schemes is tf-idf weighting (see the example below).\n",
    "The definition of term depends on the application. Typically terms are single words, keywords, or longer phrases. If the words are chosen to be the terms, the dimensionality of the vector is the number of words in the vocabulary (the number of distinct words occurring in the corpus).\n",
    "The vector space model has the following limitations:\n",
    "   1. Long documents are poorly represented because they have poor similarity values (a small scalar product and a large dimensionality)\n",
    "   2. Search keywords must precisely match document terms; word substrings might result in a \"false positive match\"\n",
    "   3. Semantic sensitivity; documents with similar context but different term vocabulary won't be associated, resulting in a \"false negative match\".\n",
    "   4. The order in which the terms appear in the document is lost in the vector space representation.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_text_2 = \"\"\"\n",
    "An algebraic model for representing text documents and any objects in general is known by the name Vector space model. It represents these as vectors of identifiers, index terms are one illustration of these. The Vector Space model was first used in the SMART Information Retrieval System, and it is utilised variously in indexing, information filtering, indexing and information retrieval.\n",
    "\n",
    "A document has representation as a vector. Every dimension is precisely related to a separate term. The way in which term is defined depends entirely on the application: typically ‘terms’ are either single words, keywords or longer phrases. The dimensionality of the vector is the number of words in the vocabulary, if it is the words that are chose to be the terms. So the same rule applies with keywords and indeed longer phrases.\n",
    "\n",
    "If a term occurs in the document, its value in the vector is non-zero. Several different ways of computing these values, additionally known as (term) weights, have been developed. One of the most famous schemes is tf-idf weighting. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text_3 = \"pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_text_3 = \"i think pagerank is a link analysis algorithm used by google that uses a system of weights attached to each element of a hyperlinked set of documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram containment features created!\n",
      "2-gram containment features created!\n",
      "3-gram containment features created!\n",
      "4-gram containment features created!\n",
      "5-gram containment features created!\n",
      "6-gram containment features created!\n",
      "7-gram containment features created!\n",
      "LCS features created!\n",
      "\n",
      "Features:  ['c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'c_6', 'c_7', 'lcs_word']\n",
      "\n",
      "1-gram containment features created!\n",
      "2-gram containment features created!\n",
      "3-gram containment features created!\n",
      "4-gram containment features created!\n",
      "5-gram containment features created!\n",
      "6-gram containment features created!\n",
      "7-gram containment features created!\n",
      "LCS features created!\n",
      "\n",
      "Features:  ['c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'c_6', 'c_7', 'lcs_word']\n",
      "\n",
      "1-gram containment features created!\n",
      "2-gram containment features created!\n",
      "3-gram containment features created!\n",
      "4-gram containment features created!\n",
      "5-gram containment features created!\n",
      "6-gram containment features created!\n",
      "7-gram containment features created!\n",
      "LCS features created!\n",
      "\n",
      "Features:  ['c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'c_6', 'c_7', 'lcs_word']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_features_1 = extract_containment_and_lcs_features(source_text_1, answer_text_1)\n",
    "extracted_features_2 = extract_containment_and_lcs_features(source_text_2, answer_text_2)\n",
    "extracted_features_3 = extract_containment_and_lcs_features(source_text_3, answer_text_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        c_1       c_2       c_3       c_4       c_5       c_6       c_7  \\\n",
      "0  0.984906  0.969697  0.954373  0.938931  0.923372  0.907692  0.891892   \n",
      "\n",
      "   lcs_word  \n",
      "0  0.985455  \n"
     ]
    }
   ],
   "source": [
    "print(extracted_features_1)\n",
    "# print(extracted_features_2)\n",
    "# print(extracted_features_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        c_1       c_6  lcs_word\n",
      "0  0.984906  0.907692  0.985455\n"
     ]
    }
   ],
   "source": [
    "selected_features = ['c_1', 'c_6', 'lcs_word']  # select your own features if you like \n",
    "\n",
    "selected_features_df = extracted_features_1[selected_features]\n",
    "# selected_features_df = extracted_features_2[selected_features]\n",
    "# selected_features_df = extracted_features_3[selected_features]\n",
    "\n",
    "print(selected_features_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on your text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your text is plagiarismed, I'll call 911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yamen\\Desktop\\NLP\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res = clf_en.predict(selected_features_df)\n",
    "print(\"Good for you, It's not plagiarismed\" if res==0 else \"Your text is plagiarismed, I'll call 911\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89acde3e661c2037e77460895ca7ebd558ab3dc972ec07cd8c69d6a502d82830"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
